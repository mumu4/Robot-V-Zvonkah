# Модель распознавания человеческой/машинной речи

[![Python Version](https://img.shields.io/badge/python-3.7%2B-blue)](https://www.python.org/)

Этот проект реализует обучение модели машинного обучения для классификации аудио на человеческую речь и машинно-синтезированную речь.

[Ссылка на веб-приложение на Flask с данной моделью](https://github.com/olesiakazakova/Robot-V-Zvonkah/tree/main).

## Требования

Для запуска проекта необходимо установить следующие библиотеки Python:
```bash
pip install scikit-learn pandas matplotlib seaborn joblib
```

## Запуск проекта

1. Склонируйте репозиторий (если есть)
2. Подготовьте файл с данными `features_dataset.csv` в формате CSV
3. Запустите основной скрипт:
```bash
python your_script_name.py
```

## Описание файлов

### features_dataset.csv

Файл содержит извлеченные акустические характеристики аудиозаписей со следующими колонками:

- **MFCC коэффициенты **: Mel-frequency cepstral coefficients - основные характеристики спектра звука
  - `mfcc_0` до `mfcc_19`

- **Дополнительные параметры**:
  - `pitch` - частота основного тона (F0)
  - `contrast_0` до `contrast_6` - спектральный контраст по 7 полосам частот

- **Метка класса**:
  - `label` - бинарная метка (0 - машинная речь, 1 - человеческая речь)

Файл формируется путем предварительной обработки аудиофайлов с помощью библиотек для анализа звука (например, librosa). Для каждого аудиофайла извлекаются указанные характеристики и добавляется соответствующая метка класса.

Другие файлы:
- `your_script_name.py` - основной скрипт для обучения модели
- `best_model.joblib` - сохраненная обученная модель (создается после запуска)
- `scaler.joblib` - сохраненный scaler для нормализации данных (создается после запуска)
## Структура проекта

Код выполняет следующие шаги:

1. Загрузка и предварительная обработка данных
2. Анализ корреляции признаков
3. Выбор наиболее информативных признаков
4. Разделение данных на обучающую и тестовую выборки
5. Масштабирование признаков
6. Обучение и оценка моделей:
   - Random Forest
   - SVM (Support Vector Machine)
7. Визуализация результатов через confusion matrix
8. Кросс-валидация лучшей модели
9. Сохранение модели и scaler'а

## Используемые признаки

Модель использует топ-5 наиболее коррелирующих с целевой переменной признаков из датасета.

## Выходные данные

После выполнения скрипта вы получите:
- Графики корреляции признаков
- Confusion matrix для каждой модели
- Отчет о классификации (precision, recall, f1-score)
- Сохраненную лучшую модель и scaler

## Настройка

Вы можете изменить:
- Путь к файлу данных (строка `pd.read_csv()`)
- Набор моделей для тестирования (раздел `models`)
- Количество выбираемых признаков (переменная `top_features`)

Для работы с собственными данными необходимо подготовить CSV-файл в том же формате, что и `features_dataset.csv`.